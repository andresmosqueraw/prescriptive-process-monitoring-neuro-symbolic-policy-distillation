# Configuración para extract_bpmn_json.py

# Rutas a repositorios externos
# REQUERIDO: Estas rutas deben estar configuradas correctamente
external_repos:
  # Ruta al repositorio ongoing-bps-state-short-term
  # DEBE estar configurada, no hay fallback automático
  ongoing_bps_state_path: /home/andrew/Documents/asistencia-graduada-phd-oscar/paper1/repos-asis-online-predictivo/whats-coming-next-short-term-simulation-of-business-processes-from-current-state/ongoing-bps-state-short-term
  
  # Ruta al repositorio Prosimos
  # DEBE estar configurada, no hay fallback automático
  prosimos_path: /home/andrew/Documents/asistencia-graduada-phd-oscar/paper1/repos-asis-online-predictivo/whats-coming-next-short-term-simulation-of-business-processes-from-current-state/libraries-used/Prosimos

# Configuración del log
log_config:
  # Ruta al archivo del log original/base (CSV, XES o XES.GZ)
  # Si es null, se debe proporcionar como argumento de línea de comandos
  # Si se especifica aquí, se puede ejecutar sin argumentos
  # NOTA: Usando muestra CSV de 300 casos para pruebas rápidas (1.0% del total)
  log_path: logs/BPI2017/bpi-challenge-2017-sample.csv
  
  # Rutas a logs BPI 2017 (para evaluación de benchmarks)
  bpi2017:
    xes_path: logs/BPI2017/bpi-challenge-2017.xes.gz
    csv_path: logs/BPI2017/bpi-challenge-2017.csv
  
  # Mapeo de columnas del log (solo necesario para CSV, XES usa nombres estándar automáticamente)
  # Para BPI 2017 en formato XES: no se necesita mapeo (Simod detecta automáticamente)
  # Para BPI 2017 en formato CSV (si se usa):
  column_mapping:
    case: "case:concept:name"
    activity: "concept:name"
    resource: "org:resource"
    start_time: "time:timestamp"  # BPI 2017 solo tiene un timestamp, usar el mismo para start y end
    end_time: "time:timestamp"
  
  # Si el log tiene nombres de columnas diferentes, ajustar aquí
  # Ejemplo para purchasing-example.csv:
  # case: "caseid"
  # activity: "task"
  # resource: "user"
  # start_time: "start_timestamp"
  # end_time: "end_timestamp"

# Configuración de Simod
simod_config:
  version: 5
  
  # Configuración común
  common:
    # NOTA: discover_data_attributes se desactiva automáticamente para datasets pequeños (<50 casos)
    # para evitar errores de train/test split. Si tienes un dataset grande, puedes activarlo.
    discover_data_attributes: true
  
  # Preprocesamiento
  preprocessing:
    enable_time_concurrency_threshold: 0.0
  
  # Control-flow (descubrimiento de estructura del proceso)
  control_flow:
    optimization_metric: "two_gram_distance"
    num_iterations: 10
    num_evaluations_per_iteration: 3
    gateway_probabilities: "discovery"
    mining_algorithm: "sm2"  # Split Miner v2
    epsilon: [0.05, 0.5]  # Rango para filtrado de aristas
    eta: [0.2, 0.7]  # Rango para umbral de filtrado
    replace_or_joins: [true, false]
    prioritize_parallelism: [true, false]
  
  # Modelo de recursos
  resource_model:
    optimization_metric: "circadian_emd"
    num_iterations: 5
    num_evaluations_per_iteration: 3
    discover_prioritization_rules: false
    discover_batching_rules: false
    resource_profiles:
      discovery_type: "differentiated"
      granularity: 60
      confidence: [0.6, 0.7]
      support: [0.05, 0.5]
      participation: 0.4
  
  # Retrasos extraneos
  extraneous_activity_delays:
    discovery_method: "eclipse-aware"
    num_iterations: 1

# Configuración de ongoing-bps-state-short-term
# Los archivos generados se guardan en data/generado-state/ (o script_config.state_output_dir)
ongoing_config:
  # Estrategia para calcular puntos de corte (cut-off points)
  # Opciones:
  #   - "fixed": 1 punto de corte fijo (usa start_time o último evento si es null)
  #   - "wip3": 3 puntos de corte basados en percentiles de Work-in-Process (10%, 50%, 90%)
  #   - "segment10": 10 puntos de corte dividiendo el intervalo temporal en segmentos iguales
  cut_strategy: "wip3"  # "fixed" | "wip3" | "segment10"
  
  # Fecha/hora de corte (cut-off) en formato ISO
  # Solo se usa si cut_strategy es "fixed"
  # Si es null y cut_strategy="fixed", usa el último evento del log como cut-off
  start_time: null  # Ejemplo: "2024-01-15T00:00:00Z"
  
  # Mapeo de columnas (se usa el mismo de log_config si no se especifica)
  # Si es null, se usa el mapeo de log_config
  column_mapping: null
  
  # Si ejecutar simulación de corto plazo después de calcular el estado
  simulate: true
  
  # Horizonte de simulación (fecha/hora en formato ISO)
  # Si es null y simulate=true, se calcula automáticamente usando horizon_days
  simulation_horizon: null  # Ejemplo: "2024-01-22T00:00:00Z"
  
  # Días desde ahora para calcular el horizonte automáticamente
  # Solo se usa si simulation_horizon es null y simulate=true
  horizon_days: 7
  
  # Número de casos a simular (solo si simulate=true)
  total_cases: 20

# Configuración del script
script_config:
  # Directorio base donde se guardarán los archivos generados por Simod
  # El nombre del log se insertará automáticamente: results/{log_name}/simod/
  # Si es null, se usa data/generado-simod dentro de la carpeta del proyecto
  output_dir: results/simod/
  
  # Directorio base donde se guardará el estado parcial (compute_state.py)
  # El nombre del log se insertará automáticamente: results/{log_name}/state/
  # Si es null, se usa data/generado-state dentro de la carpeta del proyecto
  state_output_dir: results/state/
  
  # Directorio base donde se guardará el experience buffer del RL (train_agent_in_gym.py)
  # El nombre del log se insertará automáticamente: results/{log_name}/rl/
  # Si es null, se usa data/generado-rl-train dentro de la carpeta del proyecto
  rl_output_dir: results/rl/
  
  # Directorio base donde se guardará el modelo destilado (distill_policy.py)
  # El nombre del log se insertará automáticamente: results/{log_name}/distill/
  # Si es null, se usa data dentro de la carpeta del proyecto
  distill_output_dir: results/distill/
  
  # Prefijo para directorios temporales (se crean en la carpeta del log)
  temp_dir_prefix: ".simod_temp"
  
  # Docker
  docker:
    image: "nokal/simod"
    user_id: null  # null = usar os.getuid()
    group_id: null  # null = usar os.getgid()
    # Modo de red: "bridge" (default), "host" (bypassa problemas de networking), "none"
    # "host" funciona mejor en sistemas Linux con problemas de networking de Docker
    network_mode: "host"
    # Si usar el flag --user (puede causar problemas en algunos sistemas)
    use_user_flag: true

# Configuración de entrenamiento RL (train_agent_in_gym.py)
rl_config:
  # Número de episodios de entrenamiento
  episodes: 10
  
  # Número de casos a simular por episodio
  total_cases: 50
  
  # Tasa de aprendizaje del agente RL
  learning_rate: 0.01
  
  # Exploración inicial (epsilon-greedy)
  epsilon: 0.1
  
  # Presupuesto de recursos para SymbolicSafetyGuard
  resource_budget: 100

# Configuración de destilación de política (distill_policy.py)
distill_config:
  # Ruta al archivo experience buffer (entrada)
  # El nombre del log se insertará automáticamente: results/{log_name}/rl/experience_buffer.csv
  # Si es null, se construye automáticamente usando rl_output_dir
  input_csv: null
  
  # Ruta donde se guardará el modelo destilado (salida)
  # El nombre del log se insertará automáticamente: results/{log_name}/distill/final_policy_model.pkl
  # Si es null, se construye automáticamente usando distill_output_dir
  output_model: null
  
  # Profundidad máxima del árbol de decisión
  max_depth: 5
  
  # Criterio para dividir nodos ('entropy' o 'gini')
  criterion: "entropy"
  
  # Tamaño del conjunto de prueba (0.0 a 1.0)
  test_size: 0.2
  
  # Umbral de calidad para filtrar experiencias
  # Solo se usan experiencias con reward_causal >= quality_threshold
  quality_threshold: 0.0


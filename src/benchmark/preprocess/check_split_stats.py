import pandas as pd
import numpy as np
import os

def calculate_metrics(df, name="Dataset"):
    # Definiciones de Negocio (Mismas que EDA)
    terminating_acts = ['A_Accepted', 'A_Denied', 'A_Cancelled', 'A_Complete', 
                        'O_Accepted', 'O_Refused', 'O_Cancelled', 'O_Returned', 
                        'W_Complete application']
    success_acts = ['O_Accepted']
    failure_acts = ['A_Denied', 'A_Cancelled', 'O_Refused', 'O_Cancelled', 'O_Returned']
    intervention_acts = ['W_Call after offers', 'W_Call incomplete files']
    
    # Columnas
    case_col = 'case:concept:name'
    act_col = 'concept:name'
    time_col = 'time:timestamp'
    
    # CÃ¡lculos bÃ¡sicos
    n_cases = df[case_col].nunique()
    n_events = len(df)
    n_activities = df[act_col].nunique()
    n_resources = df['org:resource'].nunique() if 'org:resource' in df.columns else 0
    
    # Agrupaciones
    last_acts = df.groupby(case_col)[act_col].last()
    
    # Terminados vs En Curso
    completed = last_acts.isin(terminating_acts).sum()
    ongoing = n_cases - completed
    
    # Ã‰xito vs Fracaso (Basado en presencia de actividad, no solo Ãºltimo evento)
    # Esto es mÃ¡s preciso para BPI 2017
    case_activities = df.groupby(case_col)[act_col].agg(set)
    
    has_success = case_activities.apply(lambda x: any(a in x for a in success_acts))
    # Fracaso: Tiene actividad de fallo Y NO tiene Ã©xito
    has_failure = case_activities.apply(lambda x: any(a in x for a in failure_acts) and not any(a in x for a in success_acts))
    
    # Solo contamos Ã©xito/fracaso sobre los terminados para consistencia con tu tabla
    # (Aunque tÃ©cnicamente se podrÃ­a medir en todos)
    completed_ids = last_acts[last_acts.isin(terminating_acts)].index
    n_success = has_success[completed_ids].sum()
    n_failed = has_failure[completed_ids].sum()
    
    # Intervenciones
    has_intervention = case_activities.apply(lambda x: any(a in x for a in intervention_acts))
    n_treated = has_intervention.sum()
    n_untreated = n_cases - n_treated
    
    # Tiempos (usar format='mixed' para manejar diferentes formatos de timestamp)
    df[time_col] = pd.to_datetime(df[time_col], utc=True, format='mixed', errors='coerce')
    case_times = df.groupby(case_col)[time_col].agg(['min', 'max'])
    durations = (case_times['max'] - case_times['min']).dt.total_seconds() / 86400  # dÃ­as
    
    # Calcular duraciÃ³n del log (del primer al Ãºltimo evento)
    log_start = df[time_col].min()
    log_end = df[time_col].max()
    log_duration_days = (log_end - log_start).days if pd.notna(log_start) and pd.notna(log_end) else 0
    
    # Calcular eventos por caso para mediana
    events_per_case = df.groupby(case_col).size()
    
    # Crear diccionario con todas las mÃ©tricas (formato completo como EDA)
    metrics = {
        'Dataset': name,
        'NÃºmero de casos': n_cases,
        'NÃºmero de eventos': n_events,
        'Actividades Ãºnicas': n_activities,
        'Recursos Ãºnicos': n_resources,
        'Casos terminados': completed,
        'Casos terminados (%)': f"{completed/n_cases:.2%}",
        'Casos en curso': ongoing,
        'Casos en curso (%)': f"{ongoing/n_cases:.2%}",
        'Casos exitosos (de terminados)': n_success if completed > 0 else 0,
        'Casos exitosos (%)': f"{n_success/completed:.2%}" if completed > 0 else "N/A",
        'Casos fracaso (de terminados)': n_failed if completed > 0 else 0,
        'Casos fracaso (%)': f"{n_failed/completed:.2%}" if completed > 0 else "N/A",
        'Casos CON intervenciÃ³n': n_treated,
        'Casos CON intervenciÃ³n (%)': f"{n_treated/n_cases:.2%}",
        'Casos SIN intervenciÃ³n': n_untreated,
        'Casos SIN intervenciÃ³n (%)': f"{n_untreated/n_cases:.2%}",
        'Eventos por caso (promedio)': round(n_events/n_cases, 2),
        'Eventos por caso (mediana)': round(events_per_case.median(), 2),
        'DuraciÃ³n promedio (dÃ­as)': round(durations.mean(), 2),
        'DuraciÃ³n mediana (dÃ­as)': round(durations.median(), 2),
        'DuraciÃ³n mÃ­nima (dÃ­as)': round(durations.min(), 2),
        'DuraciÃ³n mÃ¡xima (dÃ­as)': round(durations.max(), 2),
        'DuraciÃ³n del log (dÃ­as)': log_duration_days
    }
    
    # Crear diccionario en formato EDA (para summary_statistics.csv)
    metrics_eda_format = {
        'MÃ©trica': [
            'NÃºmero de casos',
            'NÃºmero de eventos',
            'Actividades Ãºnicas',
            'Recursos Ãºnicos',
            'Casos terminados',
            'Casos en curso (sin terminar)',
            'Casos exitosos (de terminados)',
            'Casos no exitosos/fracaso (de terminados)',
            'Casos CON intervenciÃ³n (T=1)',
            'Casos SIN intervenciÃ³n (T=0)',
            'Eventos por caso (promedio)',
            'Eventos por caso (mediana)',
            'DuraciÃ³n promedio (dÃ­as)',
            'DuraciÃ³n mediana (dÃ­as)',
            'DuraciÃ³n mÃ­nima (dÃ­as)',
            'DuraciÃ³n mÃ¡xima (dÃ­as)',
            'DuraciÃ³n del log (dÃ­as)'
        ],
        'Valor': [
            f"{n_cases:,}",
            f"{n_events:,}",
            n_activities,
            n_resources,
            f"{completed:,} ({completed/n_cases:.2%})" if n_cases > 0 else "N/A",
            f"{ongoing:,} ({ongoing/n_cases:.2%})" if n_cases > 0 else "N/A",
            f"{n_success:,} ({n_success/completed:.2%} de terminados)" if completed > 0 else "N/A",
            f"{n_failed:,} ({n_failed/completed:.2%} de terminados)" if completed > 0 else "N/A",
            f"{n_treated:,} ({n_treated/n_cases:.2%})" if n_cases > 0 else "N/A",
            f"{n_untreated:,} ({n_untreated/n_cases:.2%})" if n_cases > 0 else "N/A",
            f"{n_events/n_cases:.2f}",
            f"{events_per_case.median():.2f}",
            f"{durations.mean():.2f}",
            f"{durations.median():.2f}",
            f"{durations.min():.2f}",
            f"{durations.max():.2f}",
            f"{log_duration_days}"
        ]
    }
    
    print(f"\n--- {name} ---")
    print(f"NÃºmero de casos: {n_cases:,}")
    print(f"NÃºmero de eventos: {n_events:,}")
    print(f"Actividades Ãºnicas: {n_activities}")
    print(f"Recursos Ãºnicos: {n_resources}")
    print(f"Casos terminados: {completed:,} ({completed/n_cases:.2%})")
    print(f"Casos en curso: {ongoing:,} ({ongoing/n_cases:.2%})")
    if completed > 0:
        print(f"Casos exitosos (de terminados): {n_success:,} ({n_success/completed:.2%})")
        print(f"Casos fracaso (de terminados): {n_failed:,} ({n_failed/completed:.2%})")
    print(f"Casos CON intervenciÃ³n: {n_treated:,} ({n_treated/n_cases:.2%})")
    print(f"Casos SIN intervenciÃ³n: {n_untreated:,} ({n_untreated/n_cases:.2%})")
    print(f"Eventos por caso (promedio): {n_events/n_cases:.2f}")
    print(f"Eventos por caso (mediana): {events_per_case.median():.2f}")
    print(f"DuraciÃ³n promedio (dÃ­as): {durations.mean():.2f}")
    print(f"DuraciÃ³n mediana (dÃ­as): {durations.median():.2f}")
    print(f"DuraciÃ³n mÃ­nima (dÃ­as): {durations.min():.2f}")
    print(f"DuraciÃ³n mÃ¡xima (dÃ­as): {durations.max():.2f}")
    print(f"DuraciÃ³n del log (dÃ­as): {log_duration_days}")
    
    return metrics, metrics_eda_format

if __name__ == "__main__":
    # Calcular rutas absolutas basadas en la ubicaciÃ³n del script
    script_dir = os.path.dirname(os.path.abspath(__file__))  # src/benchmark/preprocess/
    src_dir = os.path.dirname(os.path.dirname(script_dir))  # src/
    project_root = os.path.dirname(src_dir)  # project root
    
    # Directorio donde estÃ¡n los archivos procesados
    base_dir = os.path.join(project_root, "logs", "BPI2017", "processed")
    
    train_path = os.path.join(base_dir, "bpi2017_train.csv")
    test_path = os.path.join(base_dir, "bpi2017_test.csv")
    
    print("="*80)
    print("ğŸ“Š ESTADÃSTICAS DEL SPLIT TRAIN/TEST")
    print("="*80)
    print(f"ğŸ“‚ Project root: {project_root}")
    print(f"ğŸ“‚ Base dir: {base_dir}")
    print(f"ğŸ“‚ Train file: {train_path}")
    print(f"ğŸ“‚ Test file: {test_path}")
    print()
    
    # Verificar que los archivos existan
    if not os.path.exists(train_path):
        print(f"âŒ Error: No se encontrÃ³ el archivo: {train_path}")
        if os.path.exists(base_dir):
            print(f"   Archivos disponibles en {base_dir}:")
            for f in os.listdir(base_dir):
                print(f"     - {f}")
        exit(1)
    
    if not os.path.exists(test_path):
        print(f"âŒ Error: No se encontrÃ³ el archivo: {test_path}")
        exit(1)
    
    print("ğŸ”„ Cargando archivos...")
    train_df = pd.read_csv(train_path, low_memory=False)
    test_df = pd.read_csv(test_path, low_memory=False)
    
    print(f"âœ… Train: {len(train_df):,} eventos")
    print(f"âœ… Test: {len(test_df):,} eventos")
    print()
    
    # Calcular mÃ©tricas
    train_metrics, train_eda_format = calculate_metrics(train_df, "TRAIN SET (70%)")
    test_metrics, test_eda_format = calculate_metrics(test_df, "TEST SET (30%)")
    
    # Crear DataFrame y transponer (mÃ©tricas como filas, datasets como columnas)
    stats_df = pd.DataFrame([train_metrics, test_metrics])
    
    # Transponer: las mÃ©tricas serÃ¡n las filas y los datasets las columnas
    stats_df_transposed = stats_df.set_index('Dataset').T
    stats_df_transposed.index.name = 'MÃ©trica'
    stats_df_transposed.columns.name = None
    
    # Guardar estadÃ­sticas en CSV (transpuesto)
    stats_path = os.path.join(base_dir, "split_statistics.csv")
    stats_df_transposed.to_csv(stats_path)
    
    # Generar archivo summary_statistics.csv unificado (formato EDA combinado)
    # Crear DataFrame con mÃ©tricas como filas y Train/Test como columnas
    summary_combined = pd.DataFrame({
        'MÃ©trica': train_eda_format['MÃ©trica'],
        'Train Set (70%)': train_eda_format['Valor'],
        'Test Set (30%)': test_eda_format['Valor']
    })
    
    summary_path = os.path.join(base_dir, "summary_statistics.csv")
    summary_combined.to_csv(summary_path, index=False)
    
    print("\n" + "="*80)
    print("âœ… ESTADÃSTICAS GUARDADAS")
    print("="*80)
    print(f"ğŸ“„ Archivo transpuesto: {stats_path}")
    print(f"   - {len(stats_df_transposed)} mÃ©tricas (filas)")
    print(f"   - {len(stats_df_transposed.columns)} datasets (columnas: Train y Test)")
    print(f"\nğŸ“„ Summary unificado (formato EDA): {summary_path}")
    print(f"   - {len(summary_combined)} mÃ©tricas (filas)")
    print(f"   - 2 columnas: Train Set (70%) y Test Set (30%)")